---
title: Negotiating Publicness in the AI Stack
video: /crosslucid_short.mp4
---

## A Framework for Public Claims on Resources

<Box wide>DIAGRAM: claims on resources</Box>

<Box>
AI technologies promise to affect nearly every aspect of our lives.[^1] Knowing that this transformation will play out on a societal scale requires governance and ownership mechanisms that entitle a plurality of voices to steer AI not simply as a new category of tech products, but as a public resource and infrastructure.[^2] In democratic societies, the latter are subject to varying degrees of ‘publicness’ through (1) accessibility for use, (2) maintenance as a matter of public responsibility, and (3) accountability to the public in their function. Additionally, (4) participation in strategic decisions about the development and application of resources, and (5) how the value that is derived from these resources is distributed, constitute ‘thicker’ notions of publicness, which are typically harder to render public.[^3]

Within complex innovation systems both public and private investments flow into research and development. Instead of understanding ‘public’ and ‘private’ as binary conditions attached to specific types of intermediaries (i.e. state versus market actors), FAE proposes to regard the notion of publicness as a spectrum on which the terms of public agency are negotiated, ranging from ‘thin’ to ‘thick’. ‘Thick’ public governance might apply to state-run assets funded by taxes, while ‘thin’ publicness could be obtained when/where infrastructures are freely accessible to the public but are privately owned. Between these extremes, frameworks such as commoning could be deployed to pool resources offering greater access and maintenance buy-in.[^4] [^5] Mission-driven public-private partnerships, such as those developed to build national supercomputing capabilities, leverage state-level accountability and strategic development while cooperating with private industry to deliver specialty products and services.[^6]<sup>, </sup>[^7] Non-governmental interest organisations, academia, and grassroots movements also operate within this ecosystem to address unmet needs, both at the level of general policy and on behalf of specifically affected communities.[^8]

</Box>

## AI Tech Stack

<Box>
  Today’s AI is constituted through an entanglement of resources and
  infrastructures, each layer possessing its own context and openings for
  incorporating publicness into its design. What follows is the mapping of
  entanglements through AI’s technical stack, consisting of seven hierarchical
  layers organised in two tiers. First, the ‘hardware’ tier which provides the
  physical material and machinery by means of natural resource, server networks
  and compute layers. These enable the transfer and processing of information in
  the second tier: software, from the data layer, to the model, network
  protocols and application layers. By zooming in on the stack layers, the
  interdependence between industry, states, non-governmental organisations,
  academia, and the many publics that are implicated in the creation and
  adoption of AI can be understood, highlighting the fact that ‘public AI’ is
  not just a speculative category, but a reality that requires ongoing
  development and support.[^9]
</Box>

### Software Tier

<Box>
#### Application layer

Applications in the context of this AI stack are software products that utilise machine learning models as a core part of their capability; for example, content creation services such as Stable Diffusion, ChatGPT, or Suno.ai. Other present-day applications include virtual assistants (e.g. Apple’s Siri), recommendation systems (e.g. those used by Netflix), developer tools for writing code (Github’s CoPilot), speech and language recognition tools (e.g. Google Translate), biometric identification technology (e.g. fingerprint recognition AppLock), computer sensing and simulation systems (e.g. as those operated by driverless vehicles like CARLA), search engines (e.g. Google Search and Bing), and others.

While the release of ChatGPT in November 2022 captured the public’s imagination, the history of applications that use different underlying AI capabilities (or precursors to AI) spans decades.[^10] Companies are, by default, incentivised to develop commercial products for consumers; however, governments, non-profits, and individuals also develop their own applications. For instance, in the UK the National Health Service develops applications for doctors to more accurately detect diseases using patient data.[^11] However, applications developed by the public sector are not always state-owned. Sometimes they are developed privately and licensed to the public sector. Regardless, privacy and consent are rights that are intrinsic to the individual irrespective of whether or not the tool is developed by the public sector, private sector, or state-owned.[^12]

Application development is underpinned by a robust ecosystem of open research and code sharing. The development of applications relies on platforms such as Github (for code), and HuggingFace (for machine learning models and datasets). Applications can be patented (e.g. Spotify). In the US and Europe, applications are subject to a voluntary code of practice, which extends to application providers in general.[^13]<sup>,</sup> [^14] Applications are also subject to a further round of scrutiny within digital marketplaces such as Apple’s App Store or Google Play.

</Box>

<Box>
#### Network protocols layer

Network protocols define the rules for how data is transmitted and received over a network, enabling AI applications to communicate efficiently with each other, with data sources, with models, and with end-users.

HyperText Transfer Protocol (HTTP) is the open data communication protocol underlying the World Wide Web. Its specifications standardise the exchange of information; they are publicly available and can be used by anyone.[^15] As a protocol, it is not regulated by any single governmental entity. Instead, it is maintained and developed by international standards organisations, primarily the Internet Engineering Task Force (IETF) and the World Wide Web Consortium (W3C). These organisations work through consensus-driven processes involving various stakeholders, including developers, engineers, industry representatives, and others, to ensure the protocol remains effective, interoperable, and up-to-date with evolving technological needs.[^16]

An Application Programming Interface (API), on the other hand, is a set of tools that enables the exchange of data and functionality between platforms, and integrations between different systems and devices. In AI applications, APIs are often used to access the capabilities of AI models, without interacting with the model itself, at a fee (e.g. Enterprise-grade Gemini and ChatGPT Enterprise).

</Box>

<Box>
#### Model layer

A machine learning model is a computer programme. In contrast to conventional programming, it is not manually defined through a sequence of instructions. Instead, the process of defining the computer program is automated by means of algorithms that find patterns in large quantities of exemplary data.[^17] While there are many different machine learning methods, deep learning algorithms are the current predominant subset of methods. They typically use deep artificial neural network architectures with multiple layers that can recognise features and context in data.[^18] The model configuration is defined by a set of numerical parameters that the model weights. In 2021, the concept of a ‘foundation model’ was coined to describe a large (i.e. powerful) model that can process or generate information from multiple types of data inputs, such as text, images, audio, and video.[^19] Today these foundation models are largely multimodal, meaning they can move across those types of input and output. Since training large models from scratch is expensive, requiring large amounts of data and compute resources, foundation models provide an opportunity for commercialisation. Examples of commercial foundation models include OpenAI’s GPT-4 and Google’s Gemini, while Meta’s Llama 2 and the Mistral models are open source.[^20]

Building efforts have consolidated around just a few foundation models within corporate, or privately-controlled, contexts due to the massive investments that they require.[^21] However, more recent projects have shown that smaller models are starting to compete with foundation ones.[^22] [^23] Nevertheless, only a handful of foundation models from US-based companies have the greatest number of users globally. There is debate as to whether open-sourcing foundation models should be required due to their impacts as a ‘foundational layer’ of most AI applications - Meta’s Llama 2, Stability AI’s Stable Diffusion and Google’s BERT are examples of open source foundation models emerging from proprietary companies - or whether the models should be subject to regulation by governments in jurisdictions where they are in use (or some combination of both).[^24] [^25]

Whether open-source or closed, not all model-makers reveal the contents of their training data, and it is believed that much of it is protected by copyright. Consequently, these leading AI organisations are confronting legal challenges that have yet to result in new laws.[^26]<sup>, </sup>[^27]<sup>, </sup>[^28] Meanwhile, the Responsible AI Licenses (RAIL) initiative is advocating for the development of licences for fine-tuning and downstream usage of models that curtails misuse.[^29]

</Box>

<Box>
#### Data layer

Models require high quality data for training and fine-tuning.[^30] While early efforts to create openly available, labelled datasets, for example ImageNet, improved the quality and capabilities of AI models, recent technical advances on foundation models have reduced the reliance on such resource-intensive efforts.[^31]<sup>,</sup> [^32] Instead, the web is directly scraped for training by a large-scale web crawler, resulting in the Common Crawl dataset, which is a continually-updating set of raw webpage data with extracted metadata and text.[^33] Despite increasing criticism, it still serves as the most important resource for researchers, developers, and anyone interested in analysing the vast amount of information available on the internet.[^34]

High profile lawsuits brought against companies including OpenAI, Microsoft, Stability AI, and Midjourney allege that their models infringe on copyrighted material in the training of their models.[^35] Even the use of openly accessible, or Creative Commons licensed material has engendered significant debate around concerns relating to value extraction. Web crawling can also lead to datasets unintentionally containing illegal content. For example, the community-driven open-source dataset LAION-5B has been accused of containing child sexual abuse material.[^36]<sup>,</sup> [^37] Other open data repositories, for example libraries on HuggingFace, offer developers easy access to specific datasets, while vendors such as Google Ads are given consent by users to own their data and then monetise it. Governments and the healthcare industry have high-quality datasets related to societies’ overall level of wellness relating to medical imaging and health records, as well as census and municipal data.[^38] [^39]

</Box>

### Hardware Tier

<Box>
#### Compute layer

Data-driven machine learning algorithms are reliant on high-performance computing. Graphics processing units (GPUs) are semiconductor chips originally designed for 3D graphics, but their competency in performing complex mathematical calculations at high speeds has made them hardware that is fundamental to AI systems in order for models to be trained quickly and at scale.[^40] Nvidia, AMD and Intel are currently the largest companies producing GPU hardware. Additionally, organisations that offer applications that use computational power do not pay Nvidia directly for GPUs. Instead, they access GPUs via cloud providers such as Amazon Web Services, Microsoft Azure, and Google Cloud Platform, which, in turn, buy chips in bulk from companies including Nvidia.

Because of high demand, intense global competition and geopolitical tensions have emerged surrounding the semiconductor industry; nations are vying for dominance in manufacturing, design, and supply chain control. In the past three years, particularly in response to Taiwan’s geopolitical status as the leading global chip producer, governments in the US, the EU and the UK have pushed to support national semiconductor manufacturing, research, and development through new policy positions, legislation, and by providing financial incentives. Generally, investment by outside actors in national or enterprise computing projects is regarded now as a matter of national security and global competition.[^41] Despite the USs attempts to slow R&D capacity through restrictions on key exports in China and the Middle East, China is fast catching up to state-of-the-art chip manufacturing technologies. In addition to governments, industry players have also become active. OpenAI, for example, is seeking to raise $7tn, significantly from investors in the Arabian Gulf, for its own chip production capacity.[^42]

As opposed to applications, network protocols, and small-scale models, the computing costs of foundational models means that GPUs are less accessible for small-scale entities or open innovation, raising questions about enclosure. It is a resource that has consolidated around a few key companies that service both the market and government needs.

</Box>

<Box>
#### Server networks layer

Server networks, otherwise known as ‘clouds,’ are clusters of computers that store data, run software such as AI models, and provide access to both data and models via APIs and communication protocols.[^43] To operate on the internet, server networks rely on the vast system of underwater cables which act as highways for data traffic across the planet. Over recent years, major server networks like Amazon Web Services (AWS) and Microsoft’s Azure have come to account for much of the web. The business model of server networks is a straightforward exchange of use/access for a fee. Companies that rely heavily on server architecture––such as Google––build their own.[^44] The strategic placement of servers near where they will be needed most has instigated a land grab by companies and governments as they try to secure space to build new server racks and cooling systems. National security is increasingly a major concern for countries as governments allow foreign companies to operate servers in their jurisdiction. In Guizhou, China, for instance, Apple operates the Chinese iCloud, a server network that is not connected to the global Apple iCloud.

</Box>

<Box>
#### Natural resources layer

Control over natural resources including oil, gas, and coal has shaped modern society, creating massive levels of wealth, and establishing new regulatory regimes, while simultaneously accelerating environmental breakdown and laying the foundation for the technological developments of the 20<sup>th</sup> and 21<sup>st</sup> centuries. In centuries past, the search for and sequestration of natural resources provided the foundation of colonial projects. Today, control over rare earth metals, integral to both the global rollout of renewable energy and the mass expansion of AI, will define relationships between countries and companies who have access to rare metal wealth and those who do not.

The natural resources required for AI can be broadly grouped under the headings of materials and energy. Materials e.g. silicon, gold, silver, palladium, and lithium are necessary for the fabrication of chips, servers, cables, and batteries. Energy from renewable sources (wind, solar, hydro), fossil fuels (oil, gas, coal), and nuclear reactions (fission and fusion) power the data centres, server networks, and computing operations, as well as their cooling systems.

From publicly owned oil companies such as Norway’s Equinor, to fully privatised water companies in the UK such as Thames Water, governance of natural resources across the Western world varies by location and resource. Much attention in recent years has been focused on establishing democratically, or at least more publicly, accountable energy systems across Europe with an accompanying shift away from oil, gas and coal towards renewables.[^45] This process has been accelerated by the massive profits generated by gas suppliers following the price spike resulting from the attack on Ukraine, and by accelerating climate breakdown. Less attention has been focused on the supply chains, and often weak governance models in markets for rare earth metals such as palladium and lithium, or even more traditional metal commodities, e.g. gold and silver. Often, these metals, key to a transition to renewable energy, are extracted from the territories of the former colonies of Europe, all as transnational corporations accrue massive profits from this resource extraction at the expense of their workers and of local communities.[^46]

</Box>

[^1]: OpenAI, _Developing safe & responsible AI_ [[link](https://openai.com/safety)].
[^2]: Shrey Jain _et al_., _Plural Publics _(2023) [[link](https://gettingplurality.org/2023/03/18/plural-publics/)].
[^3]: Many groups are working to define ideas of public AI; they include: The Public AI Network, _Public AI White Paper_ (2024) [[link](https://docs.google.com/document/d/1b8xYlNBCtUHCQHSsNwklR8ivqmNgCK0qeQ-LwjSEHMk/edit?usp=sharing)]; Collective Intelligence Project, Alan Turing Etc. FAE4 draws on ideas from across these frameworks. We also use the term ‘public’ following John Dewey’s conception of the term in _The Public and Its Problems_ (1927).
[^4]: This includes much of academia as well as non-profit orgs committed to stewarding the commons such as Internet Archive [[link](https://archive.org/)] and Arxiv [[link](https://info.arxiv.org/about/index.html)].
[^5]: Elinor Ostrom, _Governing the commons _(1990).
[^6]: Mariana Mazzucato, _Public Purpose: Industrial Policy’s Comeback and Government’s Role in Shared Prosperity_, (2021).
[^7]: UK AI Research Resource dubbed Isambard-AI will be one of Europe’s most powerful supercomputers. The new facility will serve as national resource for researchers and industry experts spearheading AI innovation and scientific discovery. An unprecedented £225m investment has been allotted to create UK's most powerful supercomputer in Bristol (2023) [[link](https://www.bristol.ac.uk/news/2023/november/supercomputer-announcement.html)].
[^8]: These include organisations such as Alan Turing Institute, Aptii Institute, Omydiar.
[^9]: Jurgen Habermas, public when it is ‘in service of society and not industry or government’
[^10]: OpenAI, _Introducing ChatGPT _[[link](https://openai.com/blog/chatgpt)]; William van Melle, _MYCIN: a knowledge-based consultation program for infectious disease diagnosis _(1978) [[link](https://www.sciencedirect.com/science/article/abs/pii/S0020737378800492)]; Bruce T. Lowerre, _The HARPY Speech Recognition System_ (1976) [[link](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjow8ewteyEAxV09bsIHe05B-EQFnoECBQQAQ&url=https%3A%2F%2Fstacks.stanford.edu%2Ffile%2Fdruid%3Arq916rn6924%2Frq916rn6924.pdf&usg=AOvVaw0Zbmeaotd_tVwHU9EnRvW6&opi=89978449)]; Feng-hsiung Hsu, _Behind Deep Blue: Building the Computer that Defeated the World Chess Champion_ (2002).
[^11]: Tammy Lovell,_ NHS rolls out AI tool which detects heart disease in 20 seconds _(2022) [[link](https://www.healthcareitnews.com/news/emea/nhs-rolls-out-ai-tool-which-detects-heart-disease-20-seconds)].
[^12]: In France, tax authorities used proprietary software developed by Google to identify undeclared tax revenue. See* Undeclared pools in France uncovered by AI technology* [[link](https://www.bbc.co.uk/news/world-europe-62717599)].
[^13]: In 2022, the UK government set out a voluntary code of practice that includes better reporting of software vulnerabilities and more transparency for users regarding the privacy and security of apps available in all applications stores. See _New rules for apps to boost consumer security and privacy_ [[link](https://www.gov.uk/government/news/new-rules-for-apps-to-boost-consumer-security-and-privacy#:~:text=The%20new%20measures%20include%20requiring,easy%2Dto%2Dunderstand%20way.)].
[^14]: In New York State, automated hiring apps are subject to bias testing. NYC Consumer and Worker Protection, See* Automated Employment Decision Tools: Frequently Asked Questions *(2023) [[link](https://www.nyc.gov/assets/dca/downloads/pdf/about/DCWP-AEDT-FAQ.pdf)].
[^15]: CERN, The birth of the Web [[link](https://home.web.cern.ch/science/computing/birth-web)].
[^16]: Wikipedia, _HTTP _[[link](https://en.wikipedia.org/wiki/HTTP)].
[^17]: Rishi Bommasani _et al._, _On the Opportunities and Risks of Foundation Models_ (2021) [[link](https://arxiv.org/pdf/2108.07258.pdf)].
[^18]: Yann LeCun, _Deep Learning_ (2015) [[link](https://www.nature.com/articles/nature14539)].
[^19]:
    Foundation models generally refer to transformer architecture trained on huge amounts of data and use transfer learning to perform general purpose tasks that can then be further fine-tuned into skills such as text synthesis, image manipulation, or audio generation. See Elliot Jones , _Explainer: What is a foundation model?_ (2023) [[link](https://www.adalovelaceinstitute.org/resource/foundation-models-explainer/)].
    Rishi Bommasani et al.,_ On the Opportunities and Risks of Foundation Models _(2021) [[link](https://arxiv.org/pdf/2108.07258.pdf)].

[^20]: See OpenAI’s GPT-4 [[link](https://openai.com/research/gpt-4)]; Google’s Gemeni [[link](https://gemini.google.com/?utm_source=google&utm_medium=cpc&utm_campaign=2024enGB_gemfeb&gad_source=1)]; Meta’s Llama 2 [[link](https://llama.meta.com)].
[^21]: Rishi Bommasani, et al., _On the Opportunities and Risks of Foundation Models_ (2021) [[link](https://arxiv.org/pdf/2108.07258.pdf)].
[^22]: Harsha Nori, _Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine _(2023) [[link](https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/)].
[^23]: Yi Tay, _Training Great LLMs Entirely from Ground Up in the Wilderness as a Startup_ (2024) [[link](https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness)].
[^24]: Billy Perrigo,_ Yann LeCun On How An Open Source Approach Could Shape AI _(2024) [[link](https://time.com/6691705/time100-impact-awards-yann-lecun/)].
[^25]: Stable Diffusion is a model by UK-based AI company StabilityAI, with open source code and weights [[link](https://stability.ai/news/stable-diffusion-public-release)].
[^26]:
    See Tim Bradshaw and Joe Miller, _New York Times sues Microsoft and OpenAI in copyright case_
    (2023) [[link](https://www.ft.com/content/23c15ce1-16c5-4b2f-804e-2c0da64e1972)].

[^27]: For example, an investigation by _The Atlantic_ in August of 2023 revealed that Meta partially trained its extensive language model using a dataset named Books3, which includes over 170,000 books that are either unauthorised copies or otherwise protected under copyright rules. Alex Reisner, _Revealed: The Authors Whose Pirated Books Are Powering Generative AI _(2023) [[link](https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/)].
[^28]: Because their rise has been so meteoric, the attempts to regulate models are still in infancy, with suggested measures under development in the EU, US, China, and the African Union. In the UK, the Frontier AI Taskforce, is a research team within the government to evaluate risks. In the House of Lords, a draft AI Regulation Bill has been put forth. See Robert Hart, _White House Unveils ‘Sweeping’ AI Strategy As Biden Pushes For Transparency And Safety_ (2023) [[link](https://www.forbes.com/sites/roberthart/2023/10/30/white-house-unveils-sweeping-ai-strategy-as-biden-pushes-for-transparency-and-safety/?sh=3144c3d5df04)] and _Artificial Intelligence (Regulation) Bill _(2023) [[link](https://bills.parliament.uk/publications/53068/documents/4030)].
[^29]: See Responsible AI Licenses (RAIL) initiative [[link](https://www.licenses.ai/.)].
[^30]: High-quality data is accurate, complete, reliable, and relevant information for its intended use in operations, decision-making, analysis, or processing. See Maria Priestley et al., _A Survey of Data Quality Requirements That Matter in ML Development Pipelines_ (2023).[ ](https://doi.org/10.1145/3592616)[[link](https://doi.org/10.1145/3592616)].
[^31]: Jia Deng et al*.*, _ImageNet: A Large-Scale Hierarchical Image Database _(2009) [[link](https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database)].
[^32]: Richard Sutton, _The Bitter Lesson _(2019) [[link](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)].
[^33]: Common Crawl, _Our Mission_ [[link](https://commoncrawl.org/mission)].
[^34]: Baack, Stefan, and Mozilla Insights, _Training Data for the Price of a Sandwich: Common Crawl’s Impact on Generative AI_ (2024) [[link](https://foundation.mozilla.org/en/research/library/generative-ai-training-data/common-crawl/)].
[^35]:
    USA cases: Tremblay v OpenAI (consolidated with Silverman v OpenAI and Chabon v OpenAI), 2023; Alter v OpenAI and Microsoft (consolidated with Authors Guild & ors v OpenAI), 2023; Basbanes & Ngagoyeanes v Microsoft and OpenAI, 2024; The New York Times v Microsoft and OpenAI, 2023; Chabon & ors v Meta Platforms, Inc., 2023; Kadrey v Meta Platforms, Inc. (2023); Andersen v Stability AI, 2023; Getty Images v Stability AI, 2023;
    Huckabee & ors v Meta, Bloomberg, Microsoft and The EleutherAI Institute, 2023; J.Doe 1 and J.Doe 2 v Github, Microsoft and OpenAI, 2022; Concord Music Group & ors v Anthropic PBC, 2023; Thomson Reuters v Ross Intelligence, 2023. UK: Getty Images v Stability AI, 2023.

[^36]: LAION, _Laion-5b: A New Era Of Open Large-Scale Multi-Modal Datasets _(2022) [[link](https://laion.ai/blog/laion-5b/)].
[^37]: Alex J. Champandard on X (2023) [[link](https://twitter.com/alexjc/status/1737860015262929405)].
[^38]: In the UK, Health Data Research UK is a portal that enables access to health data to enable research and development. See Health Data Research UK [[link](https://www.hdruk.ac.uk/)].
[^39]: Other public services, e.g. public transport or postal services, also create data that could be used to improve the services they provide. Over the last several years, ‘data dignity’ campaigners and associated organisations have been working to prototype new public governance models for data protection including data trusts and cooperatives. See RxC [[link](https://www.radicalxchange.org/)], Aapti Institute [[link](https://aapti.in/)], Open Data Institute [[link](https://theodi.org/about-the-odi/)], Data Empowerment Fund [[link](https://dataempowerment.fund/)], and Data Trust Initiative [[link](https://datatrusts.uk/)].
[^40]: After 2006 significant increases in computational power, thanks to advancements by Nvidia, AMD (Advanced Micro Devices), Intel, and Qualcomm, enabled the training of larger and more complex AI systems[ (citation)](https://developer.nvidia.com/about-cuda).
[^41]: Paresh Dave, _OpenAI Agreed to Buy $51 Million of AI Chips From a Startup Backed by CEO Sam Altman_ (2023) [[link](https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/)].
[^42]: Tong et al., _Exclusive: ChatGPT-owner OpenAI is exploring making its own AI chips _(2023) [[link](https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/)].
[^43]: While it is true that server networks also use computing units (e.g. CPUs) to communicate, dividing across this AI tech stack allows for the unique infrastructural and governance issues of the compute layer and server networks layer to be disambiguated.
[^44]: Debbie Weinstein, _Our $1 billion investment in a new UK data centre_ (2024) [[link](https://blog.google/around-the-globe/google-europe/united-kingdom/google-1-billion-investment-in-a-new-uk-data-centre/)].
[^45]: TUC, _Public ownership of clean power: lower bills, climate action, decent jobs_ (2022) [[link](https://www.tuc.org.uk/sites/default/files/2022-09/TUC_public%20energy%20generation_Sept2022.pdf)].
[^46]: Jake Simms and Andy Whitmore, with contributions from Kim Pratt, Unearthing injustice: A global approach to transition minerals (2023) [[link](https://foe.scot/wp-content/uploads/2023/05/Unearthing-Injustice.pdf)].
